\chapter{Budowa śródowiska}

Praktyczna realizacja zaproponowanego rozwiązania składa się z dwóch części: platformy fotogrametrycznej i zestawu skryptów.

\section{Platforma AliceVision}

\textbf{AliceVision} --- framework fotogrametryczny z otwartym kodem źródłomym, udostępniany pod licensją \textbf{MPL2}.
Platforma została stworzona aby umożliwić odtwarzanie sceny fotogrametrycznej na podstawie zbioru zdjęć lub sekwencji klatek wideo zawierających scene.
Do wybranych możliwości platformy należą:
\begin{itemize}
   \item Wyznaczanie punktów charakterystycznych --- cech sceny
   \item Parowanie zdjęć --- para jest tworzony gdy zdjęcia zawierają ten sam obiekt
   \item Zestawienie cech zdjęć
   \item Odtwarzanie struktury cech w przestrzeni 3D
   \item Lokalizacja względna i bezwzględna kamery
   \item Kalibracja kamery
   \item Utworzenie mapy głębokości sceny
   \item Odworzenie powierzchni obiektów sceny
   \item Teksturowanie obiektów sceny
\end{itemize}

Aby wykorzystać framework należy pobrać kod źródłowy projektu i zbudować go w swoim śródowisku.
Istnieje również możliwość pobrania już gotowego projektu w postaci narżedzia \textbf{Meshroom}, program ten jest swojego rodzaju powłoką graficzną dla \textbf{AliceVision} i pozwala w łatwy sposób zapoznać się z możliwościami i sposobem działania platformy.
Pliki frameworku znajdują się w katalogu głównym programu.

Zbudowany framework przedstawia sobą zestaw plików binarnych - pliki wykonywalne i biblioteki dynamiczne.
Każdy plik wykonywalny przedstawia sobą osobne narzędzie.

Wykorzystanie i komunikacja z \textbf{AliceVision} odbywa się w sposób uruchomienia odpowiedniego pliku wykonywalnego w powłoce systemu (np linii poleceń) z odpowiednim zestawem parametrów.
Wszystkie operacje odczytu/zapisu odbywają się na plikach, ścieżka których jest określana w parametrach.
Na potrzeby pracy wykorzystano następujące narzędzia:

\begin{enumerate}
   \item \textbf{CameraInit}: inicjacja danych, odczyt parametrów kamery,
   \item \textbf{FeatureExtraction}: wyszukiwanie cech,
   \item \textbf{ImageMatching}: parowanie zdjęć,
   \item \textbf{FeatureMatching}: parowanie cech,
   \item \textbf{StructureFromMotion}: odtwarzanie struktury cech w przestrzeni, lokalizacja kamery.
\end{enumerate}

Narzędzia są opisane w kolejności odpowiedniej do kolejności uruchomienia, taka kolejność zapewnia przetwarzanie potokowe danych.
Każde narzędzie jest opisane w poszczególnych rozdziałach pod względem danych wejścia/wyjścia i parametrach w zastosowanych przetwarzaniu danych.

Dla wszystkich wykorzystanych instrumentów można zadać poziom logowania (rejestracji zdarzeń) używając parametru \texttt{--verboseLevel} który przyjmuje wartości \texttt{(fatal, error, warning, info, debug, trace)}

\subsection{CameraInit}

\texttt{aliceVision\_cameraInit} --- narzędzie inicjalizacji procesu odtwarzania.
Wykrywa i zapisuje listę zbióru zdjęć.
Definiuję parametry kamery, takie jak \textbf{długość ogniskową} przeszukując bazę kamer na podstawie modelu odczytanego z metadanych zdjęcia. Istnieje możliwość obliczenia parametrów na podstawie kąta widzenia obiektywu.

\begin{itemize}
   \item Parametry wejścia:
   \begin{itemize}
      \item[--] \texttt{--imageFolder} --- ścieżka folderu zawierającego zestaw obrazów.
   \end{itemize}

   \item Parametry wyjścia:
   \begin{itemize}
      \item[--] \texttt{--output} --- \texttt{"cameraInit.sfm"}, plik zawierajcy listę danych i ustawienia początkowe sceny
   \end{itemize}

   \item Dodatkowe parametry
   \begin{itemize}
      \item[--] \texttt{ --sensorDatabase } --- baza parametrów kamer, standardowa ścieżka:

      \texttt{"aliceVision/share/aliceVision/cameraSensors.db"},
      \item[--] \texttt{ --defaultFieldOfView } --- kąt widzenia obiektywu, użyta kamera ma kąt 56 stopni.
   \end{itemize}
\end{itemize}

\subsection{FeatureExtraction}

\texttt{aliceVision\_featureExtraction} --- narzędzie dla rozpoznawania i utworzenia zbioru deskryptorów chech dla każdego zdjęcia --- transformany \textbf{SIFT}.

\begin{itemize}
   \item Parametry wejścia:
   \begin{itemize}
      \item[--] \texttt{--input} --- plik \texttt{"cameraInit.sfm"}
   \end{itemize}

   \item Parametry wyjścia:
   \begin{itemize}
      \item[--] \texttt{--output} --- ścieżka folderu dla przechowania deskryptorów, \texttt{"FeatureExtraction"}
   \end{itemize}

   \item Dodatkowe parametry
   \begin{itemize}
      \item[--] \texttt{--describerPreset} --- ustawienie transformaty \textbf{SIFT}, przyjmuje wartości \texttt{(low, medium, normal, high, ultra)}
   \end{itemize}
\end{itemize}

\subsection{ImageMatching}

\texttt{aliceVision\_imageMatching} --- narzędzie dla utworzenia zbioru par zdjęć.
Stosowanie tego narzędzia nie jest obowiązkowe.
Zalecane jest, jednak, dokonanie parowania zdjęć gdyż pozwala to ograniczyć liczbę danych wejściowych \textbf{FeatureMatching} i tym samym przyspieszyć wykonanie procesu fotogrametrii i zredukować prawdopodobieństwo wystąpienia błędnej pary cech.

\begin{itemize}
   \item Parametry wejścia:
   \begin{itemize}
      \item[--] \texttt{--input} --- plik \texttt{"cameraInit.sfm"}
      \item[--] \texttt{--featuresFolders} --- folder \texttt{"FeatureExtraction"}
   \end{itemize}

   \item Parametry wyjścia:
   \begin{itemize}
      \item[--] \texttt{--output} --- plik przechowujący wykryte pary, \texttt{"ImageMatching.txt"}
   \end{itemize}

   \item Dodatkowe parametry
   \begin{itemize}
      \item[--] \texttt{--tree} --- plik drzewa słownikowego, standardowa ścieżka:

      \texttt{"aliceVision/share/aliceVision/vlfeat\_K80L3.SIFT.tree"}
   \end{itemize}
\end{itemize}

\subsection{FeatureMatching}

\texttt{aliceVision\_featureMatching} --- narzędzie dokonujące odnalezienia i zapisania par cech dla każdej pary zdjęć.

\begin{itemize}
   \item Parametry wejścia:
   \begin{itemize}
      \item[--] \texttt{--input} --- plik \texttt{cameraInit.sfm}
      \item[--] \texttt{--featuresFolders} --- folder \texttt{"FeatureExtraction"}
   \end{itemize}

   \item Parametry wyjścia:
   \begin{itemize}
      \item[--] \texttt{--output} --- folder dla przechowania wykrytych par cech \texttt{"FeatureMatching"}
   \end{itemize}

   \item Dodatkowe parametry
   \begin{itemize}
      \item[--] \texttt{--imagePairsList} --- jeśli dokonano parowania zdjęć, plik \texttt{"ImageMatching.txt"}
   \end{itemize}
\end{itemize}

\subsection{StructureFromMotion}

\texttt{aliceVision\_incrementalSfM} --- narzędzie dla rekonstrukcji sceny. Pozwala odwarzać położenie punktów charakterystycznych w przestrzeni i odpowiadające im pozycje kamery.

\begin{itemize}
   \item Parametry wejścia:
   \begin{itemize}
      \item[--] \texttt{--input} --- plik \texttt{cameraInit.sfm}
      \item[--] \texttt{--featuresFolders} --- folder \texttt{"FeatureExtraction"}
      \item[--] \texttt{--matchesFolders} --- folder \texttt{"FeatureMatching"}
   \end{itemize}

   \item Parametry wyjścia:
   \begin{itemize}
      \item[--] \texttt{--output} --- plik przechowujący rekonstruowaną scene: cechy i pozycje kamery,  \texttt{"StructureFromMotion.sfm"}
   \end{itemize}
\end{itemize}


Zaletą \textbf{AliceVision} można nazwać wieloplatformowość, framework można zbudować dla takich systemów operacyjnych, jak Windows, Linux lub OSX.
Do zalet platformy AliceVision można również odnieść ten fakt, iż jej narzędzia zaimplementowane z wykorzystaniem takich technologii, jak na przykład \textbf{Mosek}, stosowanie których pozwala zoptymalizować i przyspieszyć wykonanie części algorytmów zwłaszcza algorytmy liniowe.
Stosowanie \textbf{OpenMP} pozwala na obliczenia wielowonkowe, a \textbf{CUDA} czy \textbf{OpenCL} umożliwiają przyrost poprzez wykonanie prostych operacji algebraicznych na procesorach graficznych.

Framework powstał i jest rozwijany jako projekt wspólny przez takie centra naukowe, jak:
\begin{itemize}
   \item Czech Technical University (CTU) in Prague, Czech Republic
   \item Institut National Polytechnique de Toulouse (Toulouse INP), France
   \item Mikros Image, Post-Production Company in Paris, France
   \item Simula Research Laboratory AS in Oslo, Norway
   \item Quine in Oslo, Norway
   \item Wspierany przez European Union’s Horizon 2020
\end{itemize}

\section{Implementacja śródowiska}

Dla realizacji zaproponowanego algorytmu i wyświetlania wyników został napisany zestaw skryptów w języku \textbf{Python} wersji 3.8.1 pozwalające na:

Dla skryptów wykonujących wprowadzono system odczytu argumentów zaimplementowany w bibliotece \textbf{\texttt{argparse}}. Przykład implementacji takiego systemu:

\begin{python}
arg_parser = argparse.ArgumentParser()

arg_parser.add_argument('--input', '-i', default="")
arg_parser.add_argument('--select_pose', nargs='+')
arg_parser.add_argument('--marker_size', default=MARKES_SIZE, type=float)
arg_parser.add_argument('--select_features', type=int)

args = arg_parser.parse_args()
\end{python}


\subsection{Proces rekonstrukcji sceny}

Dla każdego narzędzia platformy \textbf{AliceVision} została stworzona funkcja przedstawiający uproszczony interfejs narzędzia.
Przykład funkcji która tworzy polecenie i uruchamia narzędzie frameworku:

\begin{python}
def cameraInit(
 data_dir,
 cameraInit_file,
 fieldOfView = D_FIELD_OF_VIEW,
 v_level = D_VERBOSE_LEVEL,
 log_dir = D_LOG_DIR
):
    cmd = av + "cameraInit --imageFolder " + data_dir + " -o " + cameraInit_file
    cmd += " --defaultFieldOfView " + fieldOfView
    cmd += " --sensorDatabase " + SENSOR_DB
    return run("0_CameraInit", cmd, v_level, log_dir)
\end{python}

Wszystkie funkcje narzędzi były połączone w \texttt{"pipeline"} --- funkcję która przedstawia cały proces odtwarzania sceny.
Wejściem takiej funkcji są zdjęcia sceny i parametry przetwarzania, a wyjściem jest struktura opisująca rekonstruowaną scenę.

\subsection{Odczyt danych sceny}

Wynik odtwarzania sceny przez narzędzie \textbf{StructureFromMotion} jest zapisywany w postaci drzewa \textbf{json} do pliku \texttt{"StructureFromMotion.sfm"}.
Struktura użytych węzłów takiego pliku jest następująca (żółty kolor oznacza węzeł przechowujący dane):

\tikzstyle{every node}=[draw=black,thick,anchor=west]
\tikzstyle{selected}=[draw=black,fill=yellow!30]
\begin{tikzpicture}[%
   grow via three points={one child at (0.5,-0.7) and
   two children at (0.5,-0.7) and (0.5,-1.4)},
   edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}]
   \node {.sfm}
      child { node {"views"}
         child {node [selected] {"poseId":id}}
         child {node [selected] {"path":ścieżka zdjęcia}}
      }
      child [missing] {}
      child [missing] {}
      child [missing] {}
      child { node {"poses"}
         child {node [selected] {"poseId":id}}
         child { node {"pose"}
            child { node {"transform"}
               child {node [selected] {"rotation":[macierz rotacyjna]}}
               child {node [selected] {"center":[macierz translacyjna]}}
            }
         }
      }
      child [missing] {}
      child [missing] {}
      child [missing] {}
      child [missing] {}
      child [missing] {}
      child { node {"structure"}
         child {node [selected] {"color":[kolor RGB]}}
         child {node [selected] {"X":[wektor 3D]}}
         child { node {"observations"}
            child {node [selected] {"observationId":id}}
            child {node [selected] {"x":[wektor 2D]}}
         }
      };
\end{tikzpicture}

Węzeł [\texttt{”views”}] zawiera zbiór wszystkich zdjęć zestawu, każdemu zdjęciu przydzielony jest numer ujęcia \texttt{id}.

Węzeł [\texttt{”poses”}] zawiera zbiór informacji o wykrytej pozycji. Każda pozycja dpowiada jednemu z zdjęć w zestawie i zawiera macierz rotacji i translacji obserwatora.

Węzeł [\texttt{”structure”}] zawiera zbiór punktów kluczowych. Każdy z tych punktów przechowuje wektor pozycji w przestrzeni, kolor cechy i zbiór pozycji których dotyczy wraz z wektorem położenia na zdjęciu każdej pozycji.

Stosowanie biblioteki \textbf{\texttt{json}} pozwala w łatwy sposób odczytać wybrane pola takiego pliku.
Przykład kodu wyświetlający ścieżki plików ujęć:

\begin{python}
with open(input_json, "r") as read_file:
   data = json.load(read_file)

   for item in data['views']:
      print(item['path'])
\end{python}

\subsection{Rysowanie danych}

Do rysowania sceny 3D, a także rysowania wykresów i punktów na zdjęciach wykorzystana jest biblioteka \textbf{\texttt{matplotlib}}

Poniewać dokładny wektor i kolor cechy są już znane wystarczy je podać jako argument dla funkcji rysującej zbiór punktów \texttt{scatter}.
W podobny sposób rysowane są punkty kluczowe na płaszczyźnie zdjęcia(np. Rysunek \ref{fig:feature_A1_img_0}).

Aby narysować ostrosłup przedstawiający kamerę, najpierw definiowane są współrzędne wektorów ostrosłupa w punkcie (0,0,0) a następnie wektory są obracane i przesuwane poprzez mnożenie o macierz rotacji i dodanie macierzy translacji odpowiedniej pozycji.

Część kodu rysująca zbiór punktów kolorowych przedstawiających cechy i  ostrosłup przedstawiający kamerę na scenie 3D (np. Rysunek \ref{fig:preset_c2_normal}):

\begin{python}
# Zainicowac wykres w trybie trojwymiarowym:
   fig = plt.figure()
   ax = fig.add_subplot(111, projection='3d')

# Dodac punkty:
   ax.scatter(points.xs, points.ys, points.zs, marker='o', c=points.cs, s=point_size)

# Dodac kamere:
   # Narysowac uklad wspolrzednych:
   ax.quiver(*origin, a[:,0], a[:,1], a[:,2], color='b')

   # Narysowac płlaszczyzny ostroslupa:
   ax.add_collection3d(Poly3DCollection(cam, facecolors='#00ff00', edgecolors='r', alpha=.25))
   ax.add_collection3d(Poly3DCollection(cam_face, facecolors='#ffff00', edgecolors='r', alpha=.5))

   # Podpisac kamere:
   ax.text(*txt_pos, name, color='#cc0000', fontsize=14)
\end{python}

Funkcja \texttt{ax2 = ax1.twinx()} pozwala dodać nowy obszczar danych do istniejącego wykresu. W wyniku otrzymując wykres z podwójną osią Y którego dane mogą mieć róźną skalę (np. Rysunek \ref{fig:measure_c0}.

\subsection{Pomiar czasu}

Dla porównania przebiegu procesu odtwarzania wprowadzono pomiar wykonywania dla każdego kroku "pipeline". Po czym zmierzony czas się sumuje i zwraca się wraz z wynikiem odtwarzania sceny funkcją \texttt{"pipeline"}.

Proces uruchomienia funkcji \texttt{"pipeline"} jest zautomatyzowany dla każdego elementu macierzy utworzonej wektorami:
\begin{itemize}
   \item Danych wejściowych,
   \item Parametru transformaty \textbf{SIFT},
   \item Próby(aby uśrednić pomiar czasu).
\end{itemize}
