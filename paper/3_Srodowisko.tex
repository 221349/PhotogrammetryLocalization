\chapter{Budowa śródowiska}

Praktyczna realizacja zaproponowanego rozwiązania składa się z dwóch części: platformy fotogrametrycznej i zestawu skryptów.

\section{Platforma AliceVision}

\textbf{AliceVision} --- framework fotogrametryczny z otwartym kodem źródłomym, udostępniany pod licensją \textbf{MPL2}.
Platforma została stworzona aby umożliwić odtwarzanie sceny fotogrametrycznej na podstawie zbioru zdjęć lub sekwencji klatek wideo zawierających scene.
Do wybranych możliwości platformy należą:
\begin{itemize}
   \item Wyznaczanie punktów charakterystycznych --- cech sceny
   \item Parowanie zdjęć --- para jest tworzony gdy zdjęcia zawierają ten sam obiekt
   \item Zestawienie cech zdjęć
   \item Odtwarzanie struktury cech w przestrzeni 3D
   \item Lokalizacja względna i bezwzględna kamery
   \item Kalibracja kamery
   \item Utworzenie mapy głębokości sceny
   \item Odworzenie powierzchni obiektów sceny
   \item Teksturowanie obiektów sceny
\end{itemize}

Aby wykorzystać framework należy pobrać kod źródłowy projektu i zbudować go w swoim śródowisku.
Istnieje również możliwość pobrania już gotowego projektu w postaci narżedzia \textbf{Meshroom}, program ten jest swojego rodzaju powłoką graficzną dla \textbf{AliceVision} i pozwala w łatwy sposób zapoznać się z możliwościami i sposobem działania platformy.
Pliki frameworku znajdują się w katalogu głównym programu.

Zbudowany framework przedstawia sobą zestaw plików binarnych - pliki wykonywalne i biblioteki dynamiczne.
Każdy plik wykonywalny przedstawia sobą osobne narzędzie.

Wykorzystanie i komunikacja z \textbf{AliceVision} odbywa się w sposób uruchomienia odpowiedniego pliku wykonywalnego w powłoce systemu (np linii poleceń) z odpowiednim zestawem parametrów.
Wszystkie operacje odczytu/zapisu odbywają się na plikach, ścieżka których jest określana w parametrach.
Na potrzeby pracy wykorzystano następujące narzędzia:

\begin{enumerate}
   \item \textbf{CameraInit}: inicjacja danych, odczyt parametrów kamery,
   \item \textbf{FeatureExtraction}: wyszukiwanie cech,
   \item \textbf{ImageMatching}: parowanie zdjęć,
   \item \textbf{FeatureMatching}: parowanie cech,
   \item \textbf{StructureFromMotion}: odtwarzanie struktury cech w przestrzeni, lokalizacja kamery.
\end{enumerate}

Narzędzia są opisane w kolejności odpowiedniej do kolejności uruchomienia, taka kolejność zapewnia przetwarzanie potokowe danych.
Każde narzędzie jest opisane w poszczególnych rozdziałach pod względem danych wejścia/wyjścia i zastosowanych parametrach w przetwarzaniu danych.

\subsection{CameraInit}
\subsection{FeatureExtraction}
\subsection{ImageMatching}
\subsection{FeatureMatching}
\subsection{StructureFromMotion}

Zaletą \textbf{AliceVision} można nazwać wieloplatformowość, framework można zbudować dla takich systemów operacyjnych, jak Windows, Linux lub OSX.
Do zalet platformy AliceVision można również odnieść ten fakt, iż jej narzędzia zaimplementowane z wykorzystaniem takich technologii, jak na przykład \textbf{Mosek}, stosowanie których pozwala zoptymalizować i przyspieszyć wykonanie części algorytmów zwłaszcza algorytmy liniowe.
Stosowanie \textbf{OpenMP} pozwala na obliczenia wielowonkowe, a \textbf{CUDA} czy \textbf{OpenCL} umożliwiają przyrost poprzez wykonanie prostych operacji algebraicznych na procesorach graficznych.

Framework powstał i jest rozwijany jako projekt wspólny przez takie centra naukowe, jak:
\begin{itemize}
   \item Czech Technical University (CTU) in Prague, Czech Republic
   \item Institut National Polytechnique de Toulouse (Toulouse INP), France
   \item Mikros Image, Post-Production Company in Paris, France
   \item Simula Research Laboratory AS in Oslo, Norway
   \item Quine in Oslo, Norway
   \item Wspierany przez European Union’s Horizon 2020
\end{itemize}

\section{Implementacja śródowiska}

Dla realizacji zaproponowanego algorytmu i wyświetlania wyników został napisany zestaw skryptów w języku \textbf{Python} wersji 3.8.1 pozwalające na:
\begin{itemize}
   \item pojedyńcze przetwarzanie zestawu zdjęć sceny w celu odtwarzania sceny i lokalizacji kamery,
   \item wyświetlanie odtwarzonej sceny w postaci punktów kluczowych i położenia kamer,
   \item wyświetlanie wybranych punktów kluczowych w przestrzeni i odpowiednich zdjęciach,
   \item przeprowadzanie testów wydajności dla zbioru róźnych zestawów danych i parametrów przetwarzania,
\end{itemize}

\subsection{Proces rekonstrukcji sceny}

Dla każdego narzędzia platformy \textbf{AliceVision} została stworzona funkcja przedstawiający uproszczony interfejs narzędzia.

\begin{python}
def cameraInit(
 data_dir,
 cameraInit_file,
 fieldOfView = D_FIELD_OF_VIEW,
 v_level = D_VERBOSE_LEVEL,
 log_dir = D_LOG_DIR
):
    cmd = av + "cameraInit --imageFolder " + data_dir + " -o " + cameraInit_file
    cmd += " --defaultFieldOfView " + fieldOfView
    cmd += " --sensorDatabase " + SENSOR_DB
    return run("0_CameraInit", cmd, v_level, log_dir)
\end{python}

Wszystkie funkcje narzędzi były połączone w "pipeline" --- funkcję która przedstawia cały proces odtwarzania sceny.
Wejściem takiej funkcji są zdjęcia sceny i parametry przetwarzania, a wyjściem jest struktura opisująca rekonstruowaną scenę. 

\subsection{Odczyt danych sceny}

Wynik odtwarzania sceny przez narzędzie \textbf{StructureFromMotion} jest zapisywany w postaci drzewa \textbf{json} do pliku z rozszerzeniem \texttt{.sfm}.
Struktura użytych węzłów takiego pliku jest następująca (żółty kolor oznacza węzeł przechowujący dane):

\tikzstyle{every node}=[draw=black,thick,anchor=west]
\tikzstyle{selected}=[draw=black,fill=yellow!30]
\begin{tikzpicture}[%
   grow via three points={one child at (0.5,-0.7) and
   two children at (0.5,-0.7) and (0.5,-1.4)},
   edge from parent path={(\tikzparentnode.south) |- (\tikzchildnode.west)}]
   \node {.sfm}
      child { node {"views"}
         child {node [selected] {"poseId":id}}
         child {node [selected] {"path":ścieżka zdjęcia}}
      }
      child [missing] {}
      child [missing] {}
      child [missing] {}
      child { node {"poses"}
         child {node [selected] {"poseId":id}}
         child { node {"pose"}
            child { node {"transform"}
               child {node [selected] {"rotation":[macierz rotacyjna]}}
               child {node [selected] {"center":[macierz translacyjna]}}
            }
         }
      }
      child [missing] {}
      child [missing] {}
      child [missing] {}
      child [missing] {}
      child [missing] {}
      child { node {"structure"}
         child {node [selected] {"color":[kolor RGB]}}
         child {node [selected] {"X":[wektor 3D]}}
         child { node {"observations"}
            child {node [selected] {"observationId":id}}
            child {node [selected] {"x":[wektor 2D]}}
         }
      };
\end{tikzpicture}

Węzeł \texttt{”views”} zawiera zbiór wszystkich zdjęć zestawu, każdemu zdjęciu przydzielony jest numer ujęcia \texttt{id}.

Węzeł \texttt{”poses”} zawiera zbiór informacji o wykrytej pozycji. Każda pozycja dpowiada jednemu z zdjęć w zestawie i zawiera macierz rotacji i translacji obserwatora.

Węzeł \texttt{”structure”} zawiera zbiór punktów kluczowych. Każdy z tych punktów przechowuje wektor pozycji w przestrzeni, kolor cechy i zbiór pozycji których dotyczy wraz z wektorem położenia na zdjęciu każdej pozycji.

Stosowanie biblioteki \textbf{\texttt{json}} pozwala w łatwy sposób odczytać wybrane pola takiego pliku.
Przykład kodu wyświetlający ścieżki plików ujęć:

\begin{python}
with open(input_json, "r") as read_file:
   data = json.load(read_file)

   for item in data['views']:
      print(item['path'])
\end{python}

\subsection{Rysowanie danych}

Do rysowania sceny 3D, a także rysowania wykresów i punktów na zdjęciach wykorzystana jest biblioteka \textbf{\texttt{matplotlib}}

Poniewać dokładny wektor i kolor cechy są już znane wystarczy je podać jako argument dla funkcji rysującej zbiór punktów \texttt{scatter}.
W podobny sposób rysowane są punkty kluczowe na płaszczyźnie zdjęcia(np. Rysunek \ref{fig:feature_A1_img_0}).

Aby narysować ostrosłup przedstawiający kamerę, najpierw definiowane są współrzędne wektorów ostrosłupa w punkcie (0,0,0) a następnie wektory są obracane i przesuwane poprzez mnożenie o macierz rotacji i dodanie macierzy translacji odpowiedniej pozycji.

Część kodu rysująca zbiór punktów kolorowych przedstawiających cechy i  ostrosłup przedstawiający kamerę na scenie 3D (np. Rysunek \ref{fig:preset_c2_normal}):

\begin{python}
# Zainicowac wykres w trybie trojwymiarowym:
   fig = plt.figure()
   ax = fig.add_subplot(111, projection='3d')

# Dodac punkty:
   ax.scatter(points.xs, points.ys, points.zs, marker='o', c=points.cs, s=point_size)

# Dodac kamere:
   # Narysować uklad wspolrzednych:
   ax.quiver(*origin, a[:,0], a[:,1], a[:,2], color='b')

   # Narysowac płaszczyzny ostroslupa:
   ax.add_collection3d(Poly3DCollection(cam, facecolors='#00ff00', edgecolors='r', alpha=.25))
   ax.add_collection3d(Poly3DCollection(cam_face, facecolors='#ffff00', edgecolors='r', alpha=.5))

   # Podpisac kamere:
   ax.text(*txt_pos, name, color='#cc0000', fontsize=14)
\end{python}

Funkcja \texttt{ax2 = ax1.twinx()} pozwala dodać nowy obszczar danych do istniejącego wykresu. W wyniku otrzymując wykres z podwójną osią Y którego dane mogą mieć róźną skalę (np. Rysunek \ref{fig:measure_c0}.

\subsection{Pomiar czasu}
